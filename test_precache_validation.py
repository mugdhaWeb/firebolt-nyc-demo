#!/usr/bin/env python3
"""
Precache-QA-Bot Test Suite
==========================

This script validates that load_data.sh properly precaches all analytical queries
and ensures they return real data (never empty results).

Acceptance Criteria:
1. Script fails loudly on empty results
2. Zero occurrences of the empty-results message generated by the Streamlit app
3. All five main queries complete under 2√ó their historical uncached runtime
4. precache.log contains 9 successful entries (5 main + 4 filter queries)
5. All queries return > 0 rows
"""

import re
import subprocess
import sys
import time
from pathlib import Path


class PrecacheValidator:
    def __init__(self):
        self.project_root = Path(__file__).parent
        self.precache_log = self.project_root / "precache.log"
        self.ci_run_log = self.project_root / "ci_run.log"
        self.results = {}

    def run_test_suite(self) -> bool:
        """Run the complete test suite and return True if all tests pass."""
        print("üß™ Precache-QA-Bot Test Suite")
        print("=" * 50)

        # Test 1: Verify Firebolt Core is accessible
        if not self._test_firebolt_connectivity():
            return False

        # Test 2: Run load_data.sh and capture logs
        if not self._test_load_data_execution():
            return False

        # Test 3: Validate precache.log exists and has correct entries
        if not self._test_precache_log_validation():
            return False

        # Test 4: Verify no empty result messages
        if not self._test_no_empty_results():
            return False

        # Test 5: Test query performance (cached vs uncached)
        if not self._test_query_performance():
            return False

        # Test 6: Validate actual query results
        if not self._test_query_results_validation():
            return False

        print("\nüéâ All tests passed! Precaching is working correctly.")
        return True

    def _test_firebolt_connectivity(self) -> bool:
        """Test if Firebolt Core is running and accessible."""
        print("\nüîç Test 1: Firebolt Core Connectivity")

        try:
            result = subprocess.run(
                ["docker", "exec", "firebolt-core", "fb", "-C", "-c", "SELECT 1"],
                check=False, capture_output=True,
                text=True,
                timeout=10,
            )

            if result.returncode == 0:
                print("‚úÖ Firebolt Core is accessible")
                return True
            print(f"‚ùå Firebolt Core connection failed: {result.stderr}")
            return False

        except subprocess.TimeoutExpired:
            print("‚ùå Firebolt Core connection timed out")
            return False
        except Exception as e:
            print(f"‚ùå Error testing connectivity: {e}")
            return False

    def _test_load_data_execution(self) -> bool:
        """Execute load_data.sh and capture all output."""
        print("\nüîç Test 2: Load Data Execution")

        try:
            # Remove existing logs
            if self.precache_log.exists():
                self.precache_log.unlink()
            if self.ci_run_log.exists():
                self.ci_run_log.unlink()

            # Run load_data.sh and capture all output
            start_time = time.time()
            result = subprocess.run(
                ["./load_data.sh"],
                check=False, cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=300,  # 5 minute timeout
            )

            execution_time = time.time() - start_time

            # Save full logs
            with open(self.ci_run_log, "w") as f:
                f.write("=== LOAD DATA EXECUTION LOG ===\n")
                f.write(f"Start time: {time.ctime(start_time)}\n")
                f.write(f"Execution time: {execution_time:.2f}s\n")
                f.write(f"Exit code: {result.returncode}\n\n")
                f.write("=== STDOUT ===\n")
                f.write(result.stdout)
                f.write("\n=== STDERR ===\n")
                f.write(result.stderr)

            if result.returncode == 0:
                print(
                    f"‚úÖ load_data.sh completed successfully in {execution_time:.2f}s"
                )
                return True
            print(f"‚ùå load_data.sh failed with exit code {result.returncode}")
            print(f"Check {self.ci_run_log} for details")
            return False

        except subprocess.TimeoutExpired:
            print("‚ùå load_data.sh timed out after 5 minutes")
            return False
        except Exception as e:
            print(f"‚ùå Error executing load_data.sh: {e}")
            return False

    def _test_precache_log_validation(self) -> bool:
        """Validate precache.log exists and has correct format."""
        print("\nüîç Test 3: Precache Log Validation")

        if not self.precache_log.exists():
            print("‚ùå precache.log not found")
            return False

        try:
            with open(self.precache_log) as f:
                log_content = f.read()

            # Count success entries
            success_entries = re.findall(r"‚úÖ SUCCESS", log_content)

            # Expected queries: Q1, Q2, Q3, Q4, Q5, STREETS, AMOUNTS, VEHICLES, SAMPLE = 9 total
            expected_count = 9
            actual_count = len(success_entries)

            print(f"üìä Found {actual_count}/{expected_count} successful query entries")

            if actual_count >= expected_count:
                print("‚úÖ All required queries validated successfully")

                # Check for specific queries
                required_queries = [
                    "Q1",
                    "Q2",
                    "Q3",
                    "Q4",
                    "Q5",
                    "STREETS",
                    "AMOUNTS",
                    "VEHICLES",
                    "SAMPLE",
                ]
                missing_queries = []

                for query in required_queries:
                    if (
                        f"| {query} |" not in log_content
                        and f"| {query} | ‚úÖ SUCCESS" not in log_content
                    ):
                        missing_queries.append(query)

                if missing_queries:
                    print(f"‚ö†Ô∏è  Missing queries in log: {missing_queries}")
                else:
                    print("‚úÖ All required queries present in log")

                return True
            print(f"‚ùå Only {actual_count}/{expected_count} queries validated")
            return False

        except Exception as e:
            print(f"‚ùå Error reading precache.log: {e}")
            return False

    def _test_no_empty_results(self) -> bool:
        """Test that no queries returned empty results."""
        print("\nüîç Test 4: No Empty Results Validation")

        # Check precache.log for failed entries
        try:
            with open(self.precache_log) as f:
                log_content = f.read()

            failed_entries = re.findall(r"FAILED.*No data rows", log_content)
            empty_result_patterns = [
                "Query executed successfully but returned no " + "results",
                "returned no data rows",
                "| 0 rows",
            ]

            violations = []
            for pattern in empty_result_patterns:
                if pattern in log_content:
                    violations.append(pattern)

            if failed_entries:
                print(f"‚ùå Found {len(failed_entries)} queries with no data")
                return False
            if violations:
                print(f"‚ùå Found empty result violations: {violations}")
                return False
            print("‚úÖ No empty result violations found")
            return True

        except Exception as e:
            print(f"‚ùå Error checking for empty results: {e}")
            return False

    def _test_query_performance(self) -> bool:
        """Test that cached queries perform better than historical uncached times."""
        print("\nüîç Test 5: Query Performance Validation")

        try:
            with open(self.precache_log) as f:
                log_content = f.read()

            # Extract timing information
            timing_pattern = r"\| (Q[1-5]) \| ([\d.]+)s"
            timings = re.findall(timing_pattern, log_content)

            # Historical uncached times (rough estimates in seconds)
            historical_times = {
                "Q1": 0.5,  # Simple aggregation
                "Q2": 1.0,  # GROUP BY with ORDER BY
                "Q3": 1.2,  # Complex GROUP BY
                "Q4": 0.8,  # Date extraction and GROUP BY
                "Q5": 0.3,  # Simple SELECT with LIMIT
            }

            performance_ok = True
            for query, time_str in timings:
                actual_time = float(time_str)
                expected_max = (
                    historical_times.get(query, 1.0) * 2
                )  # 2√ó historical time

                if actual_time <= expected_max:
                    print(
                        f"‚úÖ {query}: {actual_time:.3f}s (within {expected_max:.3f}s limit)"
                    )
                else:
                    print(
                        f"‚ùå {query}: {actual_time:.3f}s (exceeds {expected_max:.3f}s limit)"
                    )
                    performance_ok = False

            return performance_ok

        except Exception as e:
            print(f"‚ùå Error checking query performance: {e}")
            return False

    def _test_query_results_validation(self) -> bool:
        """Test that each query actually returns meaningful data."""
        print("\nüîç Test 6: Query Results Validation")

        # Test a few key queries to ensure they return expected data structures
        test_queries = {
            "Q1_validation": "SELECT COUNT(*) as count FROM (SELECT COUNT(*) as total_violations, SUM(calculated_fine_amount) as total_fines FROM violations WHERE calculated_fine_amount > 0) subq WHERE total_violations > 1000000",
            "Q2_validation": "SELECT COUNT(*) as count FROM (SELECT street_name, COUNT(*) as total_violations FROM violations WHERE street_name IS NOT NULL AND street_name != '' GROUP BY street_name LIMIT 10) subq",
            "STREETS_validation": "SELECT COUNT(*) as count FROM (SELECT DISTINCT street_name FROM violations WHERE street_name IS NOT NULL AND street_name != '' LIMIT 100) subq WHERE count >= 90",
        }

        validation_ok = True
        for test_name, query in test_queries.items():
            try:
                result = subprocess.run(
                    ["docker", "exec", "firebolt-core", "fb", "-C", "-c", query],
                    check=False, capture_output=True,
                    text=True,
                    timeout=30,
                )

                if result.returncode == 0 and result.stdout.strip():
                    # Extract the count value
                    lines = result.stdout.strip().split("\n")
                    data_lines = [
                        line
                        for line in lines
                        if line
                        and not line.startswith("Time:")
                        and not line.startswith("Request Id:")
                    ]

                    if len(data_lines) >= 2:  # Header + data
                        print(f"‚úÖ {test_name}: Data validation passed")
                    else:
                        print(f"‚ùå {test_name}: Insufficient data returned")
                        validation_ok = False
                else:
                    print(f"‚ùå {test_name}: Query failed")
                    validation_ok = False

            except Exception as e:
                print(f"‚ùå {test_name}: Error during validation: {e}")
                validation_ok = False

        return validation_ok

    def print_summary(self):
        """Print a summary of the test results."""
        print("\nüìã Test Summary")
        print("=" * 30)

        if self.precache_log.exists():
            try:
                with open(self.precache_log) as f:
                    log_content = f.read()

                success_count = len(re.findall(r"‚úÖ SUCCESS", log_content))
                print(f"‚úÖ Successful queries: {success_count}/9")

                # Extract timing summary
                timings = re.findall(
                    r"\| (Q[1-5]|STREETS|AMOUNTS|VEHICLES|SAMPLE) \| ([\d.]+)s",
                    log_content,
                )
                if timings:
                    total_time = sum(float(time) for _, time in timings)
                    print(f"‚è±Ô∏è  Total precache time: {total_time:.3f}s")
                    print(f"üìä Average query time: {total_time / len(timings):.3f}s")

            except Exception as e:
                print(f"Error reading summary: {e}")

        if self.ci_run_log.exists():
            print(f"üìÑ Full execution log: {self.ci_run_log}")

        print(f"üìÑ Precache validation log: {self.precache_log}")


def main():
    """Main test execution."""
    validator = PrecacheValidator()

    try:
        success = validator.run_test_suite()
        validator.print_summary()

        if success:
            print("\nüéâ PASS: All precaching tests passed!")
            sys.exit(0)
        else:
            print("\n‚ùå FAIL: One or more tests failed!")
            sys.exit(1)

    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Test interrupted by user")
        sys.exit(130)
    except Exception as e:
        print(f"\n‚ùå Unexpected error: {e}")
        sys.exit(2)


if __name__ == "__main__":
    main()
